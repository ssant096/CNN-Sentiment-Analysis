{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8db10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd838fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fa3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = ['and', 'at', 'the', 'yet', 'so', 'because', 'on', 'of', 'to', 'as',' in', 'his', 'her', 'she', 'him',\n",
    "            'them', 'they', 'it', 'hers', 'their', 'its', 'theirs', 'with', 'said', 'for', 'after', 'will', 'that',\n",
    "            'about', 'who', 'by', 'all', 'where', 'over', 'year', 'years', 'continue', 'two', 'three', 'four', 'five',\n",
    "            'six', 'seven', 'eight', 'nine', 'ten', 'other', 'into']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bf2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimWord(word):\n",
    "    w = word\n",
    "    \n",
    "    if ((w[len(w)-1] == \",\")or(w[len(w)-1] == \".\")or(w[len(w)-1] == \"?\")\n",
    "        or(w[len(w)-1] == \"!\")or(w[len(w)-1] == \"’\")or(w[len(w)-1] == \":\")\n",
    "        or(w[len(w)-1]==\"\\\"\")or(w[len(w)-1]==\"-\")or(w[len(w)-1]==\"'\")):\n",
    "        w = w[:len(w)-1]\n",
    "                        \n",
    "    if((w[0]==\"'\")or(w[0]==\"’\")or(w[0]==\"\\\"\")or(w[0]==\"-\")):\n",
    "        w = w[1:]\n",
    "                        \n",
    "    if ((w[len(w)-2:len(w)] == \"’s\")or(w[len(w)-2:len(w)] == \"\\'s\")):\n",
    "        w = w[:len(w)-2]\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7906bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeArticlesCNN(w, rBank, dBank):\n",
    "    dataFile = open(\"cnn.txt\", \"a\")\n",
    "    \n",
    "    www = w\n",
    "    www = requests.get(www,headers = headers)\n",
    "\n",
    "    if (www.status_code != 200):\n",
    "        return \"Error\"\n",
    "\n",
    "    soup = BeautifulSoup(www.text, 'html.parser')    \n",
    "    \n",
    "    headlineBlocks = soup.find_all('span', class_ = 'sitemap-link')\n",
    "    headlineBlocks = headlineBlocks[1:]\n",
    "    #for i in headlineBlocks:\n",
    "    #    print(i)\n",
    "    x=0\n",
    "    for currentHeadline in headlineBlocks:\n",
    "        x+=1\n",
    "        articleWWW = str(currentHeadline.find('a')).split(\"\\\"\")[1]\n",
    "        #print(articleWWW)\n",
    "        articleWWW = requests.get(articleWWW,headers = headers)\n",
    "        \n",
    "        if (www.status_code != 200):\n",
    "            return \"Error\"\n",
    "        \n",
    "        soup = BeautifulSoup(articleWWW.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------------------------------------------------------------------\n",
    "        headline = soup.find('h1', class_=\"headline__text inline-placeholder\")\n",
    "        #print(headline.text.split())\n",
    "        \n",
    "        r = False\n",
    "        d = False\n",
    "        try:\n",
    "            headline_words = headline.text.split()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        for word in headline_words:\n",
    "            try:\n",
    "                word = trimWord(word)\n",
    "                word = word.lower()\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            if(word in stopWords):\n",
    "                continue\n",
    "            \n",
    "            if (not r):\n",
    "                r = (word in rBank)\n",
    "            if (not d):\n",
    "                d = (word in dBank)\n",
    "            \n",
    "            \n",
    "        if (not ((r or d) & (not (r&d)))):\n",
    "            continue\n",
    "        #------------------------------------------------------------------------------------------------------------- \n",
    "        paragraph = soup.find_all('p', class_ = 'paragraph inline-placeholder')\n",
    "        \n",
    "        try:\n",
    "            if (r):\n",
    "                dataFile.write(paragraph[0].text + paragraph[1].text + ' r     \\n')\n",
    "            if (d):\n",
    "                dataFile.write(paragraph[0].text + paragraph[1].text + ' d     \\n')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    dataFile.close()\n",
    "    \n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2588191",
   "metadata": {},
   "outputs": [],
   "source": [
    "www = \"https://www.multistate.us/resources/2023-governors-and-legislatures\"\n",
    "\n",
    "www = requests.get(www,headers = headers)\n",
    "if (www.status_code != 200):\n",
    "    print(\"Error\")\n",
    "\n",
    "soup = BeautifulSoup(www.text, 'html.parser')\n",
    "\n",
    "politicians = []\n",
    "parties = []\n",
    "\n",
    "govBlocks = soup.find_all(\"td\", class_ = \"gov left\")\n",
    "\n",
    "for govBlock in govBlocks:\n",
    "    \n",
    "    vect = govBlock.text.split()\n",
    "    governor = vect[1]\n",
    "    party = vect[len(vect)-1][1]\n",
    "    \n",
    "    if(party==\"D\"):\n",
    "        party = \"Democratic\"\n",
    "    if(party==\"R\"):\n",
    "        party = \"Republican\"\n",
    "            \n",
    "    politicians.append(governor.lower())\n",
    "    parties.append(party)\n",
    "\n",
    "www = \"https://ballotpedia.org/List_of_current_members_of_the_U.S._Congress\"\n",
    "\n",
    "www = requests.get(www,headers = headers)\n",
    "if (www.status_code != 200):\n",
    "    print(\"Error\")\n",
    "\n",
    "soup = BeautifulSoup(www.text, 'html.parser')\n",
    "        \n",
    "people = soup.find_all('tr')\n",
    "\n",
    "for i in people:\n",
    "    try:\n",
    "        name = i.find('td', style=\"padding-left:10px;text-align:center;\").text\n",
    "        party = \"\"\n",
    "        try:\n",
    "            party = i.find(\"td\", class_ = \"partytd Democratic\").text\n",
    "            party = \"Democratic\"\n",
    "        except:\n",
    "            party = i.find(\"td\", class_ = \"partytd Republican\").text\n",
    "            party = \"Republican\"\n",
    "        \n",
    "        names = name.split()\n",
    "        last_name = names[len(names)-1]\n",
    "        politicians.append(last_name.lower())\n",
    "        parties.append(party)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92f04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "additionalRepublicans = ['trump', 'g.o.p.', 'gop', 'republicans', 'republican', 'conservatives', 'pence']\n",
    "additionalDemocrats = ['pelosi', 'biden', 'democrat', 'democrats', 'liberals', 'kamala', 'obama', 'bernie', 'clinton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ecf9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = \"\"\n",
    "pdf = pd.DataFrame()\n",
    "pdf['Politician'] = politicians\n",
    "pdf['Party'] = parties\n",
    "\n",
    "for a in additionalRepublicans:\n",
    "    pdf.loc[len(pdf['Party'].values)] = a.lower()\n",
    "    pdf['Party'].loc[len(pdf['Party'].values)-1] = 'Republican'\n",
    "\n",
    "for b in additionalDemocrats:\n",
    "    pdf.loc[len(pdf['Party'].values)] = b.lower()\n",
    "    pdf['Party'].loc[len(pdf['Party'].values)-1] = 'Democratic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f53857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove some politicians with generic names\n",
    "removePoliticians = ['justice', 'cooper', 'cox', 'murphy', 'green', 'greene', 'little', 'moore', 'reeves', 'shapiro', \n",
    "                     'lee', 'scott', 'jr.', 'miller', 'rodgers', 'good', 'fitzgerald', 'smith', 'tiffany', 'carson', \n",
    "                    'stevens', 'james', 'harris', 'davis', 'carter', 'clark', 'jackson', 'collins', 'bush', 'thompson'\n",
    "                    'gordon', 'young', 'paul', 'peters', 'brown', 'murray', 'iii', 'johnson' 'carl' 'rogers', 'strong',\n",
    "                    'crane', 'hill', 'kim', 'steel', 'crow', 'courtney', 'bean', 'frost', 'posey', 'wilson', 'williams',\n",
    "                    'allen', 'simpson', 'flood', 'ryan', 'ross', 'adams', 'edwards', 'jordan', 'lucas', 'cole', 'rose',\n",
    "                    'fallon', 'roy', 'drew', 'clarke', 'wild', 'gordon', 'kennedy', 'schmitt', 'booker', 'vance', \n",
    "                     'mullin', 'reed', 'graham', 'evans', 'dean', 'duncan', 'case', 'hunt', 'golden', 'carey', 'joyce',\n",
    "                    'johnson','graves', 'davidson', 'franklin', 'cassidy', 'garcia', 'mills', 'thompson', 'curtis',\n",
    "                    'stewart', 'guest', 'cloud', 'banks', 'self', 'waters', 'buck', 'game', 'foster', 'rounds', 'carl',\n",
    "                    'kiley', 'mast', 'rogers', 'owens', 'fry', 'norman', 'crenshaw']\n",
    "\n",
    "for r in removePoliticians:\n",
    "    try:\n",
    "        pdf = pdf.drop(pdf.index[pdf['Politician'] == r.lower()].tolist())\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "748699e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "republicans = list(pdf[pdf['Party'] == 'Republican']['Politician'])\n",
    "democrats = list(pdf[pdf['Party'] == 'Democratic']['Politician'])\n",
    "#print(democrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f01231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ivey', 'dunleavy', 'huckabee', 'desantis', 'kemp', 'holcomb', 'reynolds', 'parson', 'gianforte', 'pillen', 'lombardo', 'sununu', 'burgum', 'dewine', 'stitt', 'mcmaster', 'noem', 'abbot', 'youngkin', 'britt', 'tuberville', 'murkowski', 'sullivan', 'boozman', 'cotton', 'rubio', 'crapo', 'risch', 'braun', 'ernst', 'grassley', 'marshall', 'moran', 'mcconnell', 'hyde-smith', 'wicker', 'hawley', 'daines', 'fischer', 'ricketts', 'budd', 'tillis', 'cramer', 'hoeven', 'lankford', 'thune', 'blackburn', 'hagerty', 'cornyn', 'cruz', 'romney', 'capito', 'barrasso', 'lummis', 'aderholt', 'palmer', 'radewagen', 'schweikert', 'biggs', 'ciscomani', 'lesko', 'gosar', 'crawford', 'womack', 'westerman', 'lamalfa', 'mcclintock', 'duarte', 'mccarthy', 'valadao', 'obernolte', 'calvert', 'issa', 'boebert', 'lamborn', 'gaetz', 'dunn', 'cammack', 'rutherford', 'waltz', 'webster', 'bilirakis', 'luna', 'buchanan', 'steube', 'donalds', 'diaz-balart', 'salazar', 'gimenez', 'ferguson', 'mccormick', 'clyde', 'loudermilk', 'moylan', 'fulcher', 'bost', 'lahood', 'yakym', 'baird', 'spartz', 'pence', 'bucshon', 'houchin', 'miller-meeks', 'hinson', 'nunn', 'feenstra', 'mann', 'laturner', 'estes', 'guthrie', 'massie', 'barr', 'scalise', 'higgins', 'letlow', 'bergman', 'moolenaar', 'huizenga', 'walberg', 'mcclain', 'finstad', 'emmer', 'fischbach', 'stauber', 'kelly', 'ezell', 'wagner', 'luetkemeyer', 'alford', 'burlison', 'zinke', 'rosendale', 'bacon', 'amodei', 'lalota', 'garbarino', 'devolder-santos', \"d'esposito\", 'malliotakis', 'lawler', 'molinaro', 'stefanik', 'langworthy', 'tenney', 'foxx', 'rouzer', 'bishop', 'hudson', 'mchenry', 'armstrong', 'wenstrup', 'latta', 'turner', 'balderson', 'hern', 'brecheen', 'bice', 'bentz', 'chavez-deremer', 'fitzpatrick', 'meuser', 'perry', 'smucker', 'reschenthaler', 'kelly', 'mace', 'timmons', 'harshbarger', 'burchett', 'fleischmann', 'desjarlais', 'ogles', 'kustoff', 'moran', 'gooden', 'ellzey', 'luttrell', 'mccaul', 'pfluger', 'granger', 'weber', 'cruz', 'sessions', 'arrington', 'nehls', 'gonzales', 'duyne', 'burgess', 'babin', 'wittman', 'kiggans', 'cline', 'griffith', 'newhouse', 'mooney', 'steil', 'orden', 'grothman', 'gallagher', 'hageman', 'trump', 'g.o.p.', 'gop', 'republicans', 'republican', 'conservatives', 'pence']\n"
     ]
    }
   ],
   "source": [
    "#print(republicans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb51969",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('cnn.txt', 'w').close()\n",
    "for month in range(1,3):\n",
    "    print(scrapeArticlesCNN(\"https://www.cnn.com/politics/article/sitemap-2023-\" + str(month) + \".html\", republicans, democrats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f24d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
